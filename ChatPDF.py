import streamlit as st
from openai import OpenAI
import tempfile

st.set_page_config(page_title="ChatPDF", layout="centered")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "vector_store_id" not in st.session_state:
    st.session_state.vector_store_id = None
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None

# --- ì‚¬ì´ë“œë°” ---
st.sidebar.header("ğŸ” OpenAI API ì„¤ì •")
st.session_state.api_key = st.sidebar.text_input("API Key ì…ë ¥", type="password", value=st.session_state.api_key)

# Clear ë²„íŠ¼
if st.sidebar.button("ğŸ—‘ï¸ Clear Vector Store"):
    st.session_state.chat_history = []
    client = OpenAI(api_key=st.session_state.api_key)
    if st.session_state.vector_store_id:
        try:
            client.beta.vector_stores.delete(st.session_state.vector_store_id)
            st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
    st.session_state.vector_store_id = None
    st.session_state.assistant_id = None

st.title("ğŸ“„ ChatPDF - PDF ê¸°ë°˜ ì±—ë´‡")

# --- PDF ì—…ë¡œë” ---
uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

# --- ì§ˆë¬¸ ì…ë ¥ ---
question = st.text_input("PDFì— ëŒ€í•´ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:")

# --- ì±—ë´‡ ì‘ë‹µ ì²˜ë¦¬ ---
def chat_with_pdf(pdf_file, query):
    client = OpenAI(api_key=st.session_state.api_key)

    # 1. ì„ì‹œ íŒŒì¼ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(pdf_file.read())
        tmp_path = tmp.name

    # 2. íŒŒì¼ ì—…ë¡œë“œ
    uploaded = client.files.create(file=open(tmp_path, "rb"), purpose="assistants")

    # 3. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° íŒŒì¼ ì—°ê²°
    vector_store = client.beta.vector_stores.create(name="ChatPDF VectorStore")
    client.beta.vector_stores.file_batches.upload_and_poll(vector_store.id, files=[uploaded.id])
    st.session_state.vector_store_id = vector_store.id

    # 4. Assistant ìƒì„±
    assistant = client.beta.assistants.create(
        name="PDF Chat Assistant",
        instructions="ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ PDF ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.",
        tools=[{"type": "file_search"}],
        model="gpt-4"
    )
    st.session_state.assistant_id = assistant.id

    # 5. Thread ìƒì„± ë° ë©”ì‹œì§€ ì „ì†¡
    thread = client.beta.threads.create()
    client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=query
    )

    # 6. Run ì‹¤í–‰
    run = client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=assistant.id,
        tool_resources={"file_search": {"vector_store_ids": [vector_store.id]}}
    )

    # 7. ì‘ë‹µ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    import time
    while True:
        run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        if run_status.status == "completed":
            break
        elif run_status.status == "failed":
            return "âŒ ì‹¤í–‰ ì‹¤íŒ¨"
        time.sleep(1)

    # 8. ì‘ë‹µ ì¶œë ¥
    messages = client.beta.threads.messages.list(thread_id=thread.id)
    for msg in reversed(messages.data):
        if msg.role == "assistant":
            return msg.content[0].text.value
    return "â“ ì‘ë‹µ ì—†ìŒ"

# --- ì§ˆë¬¸ ì²˜ë¦¬ ---
if st.button("ì „ì†¡") and uploaded_file and question.strip():
    with st.spinner("ğŸ“š GPTê°€ PDFë¥¼ ë¶„ì„í•˜ê³  ìˆì–´ìš”..."):
        response = chat_with_pdf(uploaded_file, question)
        st.session_state.chat_history.append({"question": question, "answer": response})

# --- ëŒ€í™” ì¶œë ¥ ---
for chat in st.session_state.chat_history:
    st.markdown(f"**ğŸ™‹ ì§ˆë¬¸:** {chat['question']}")
    st.markdown(f"**ğŸ¤– GPT ì‘ë‹µ:** {chat['answer']}")
