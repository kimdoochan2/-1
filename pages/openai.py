import streamlit as st
from PyPDF2 import PdfReader
from openai import OpenAI
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS

# ------------------- Streamlit ì•± -------------------
st.title("ğŸ“„ ChatPDF: PDF ë¬¸ì„œì™€ ëŒ€í™”í•˜ê¸° (FAISS ë²„ì „)")

# ------------------- API Key ì…ë ¥ -------------------
st.sidebar.header("ì„¤ì •")
user_api_key = st.sidebar.text_input("ğŸ”‘ OpenAI API Key ì…ë ¥", type="password")

if user_api_key:
    openai_client = OpenAI(api_key=user_api_key)

    if "vectorstore" not in st.session_state:
        st.session_state.vectorstore = None

    def extract_text_from_pdf(uploaded_file):
        reader = PdfReader(uploaded_file)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
        return text

    def create_vector_store(text):
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        texts = text_splitter.split_text(text)

        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)
        vectorstore = FAISS.from_texts(texts, embeddings)
        return vectorstore

    def chat_with_pdf(vectorstore, user_question):
        docs = vectorstore.similarity_search(user_question, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])
        prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\në¬¸ì„œ:\n{context}\n\nì§ˆë¬¸: {user_question}\në‹µë³€:" 

        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ë¶„ì„í•´ì£¼ëŠ” ìœ ëŠ¥í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content

    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (1ê°œë§Œ ê°€ëŠ¥)", type=["pdf"])

    if uploaded_file:
        with st.spinner("PDF í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¥¼ êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤..."):
            pdf_text = extract_text_from_pdf(uploaded_file)
            vectorstore = create_vector_store(pdf_text)
            st.session_state.vectorstore = vectorstore
            st.success("ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ê³  ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")

    if st.session_state.vectorstore:
        question = st.text_input("ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:")

        if question:
            with st.spinner("GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                answer = chat_with_pdf(st.session_state.vectorstore, question)
                st.markdown(f"**ë‹µë³€:** {answer}")

        if st.button("Clear (ë¬¸ì„œ ì‚­ì œ)"):
            st.session_state.vectorstore = None
            st.success("ë¬¸ì„œ ë° ì¸ë±ìŠ¤ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œ í›„ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.")
else:
    st.warning("ë¨¼ì € ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
