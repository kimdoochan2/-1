import openai
st.sidebar.write("ğŸ“¦ OpenAI ë²„ì „:", openai.__version__)

import streamlit as st
from openai import OpenAI
import tempfile
import time

st.set_page_config(page_title="ChatPDF", layout="centered")

# --- ì„¸ì…˜ ì´ˆê¸°í™” ---
if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "vector_store_id" not in st.session_state:
    st.session_state.vector_store_id = None
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- API í‚¤ ì…ë ¥ ---
st.sidebar.header("ğŸ” OpenAI ì„¤ì •")
st.session_state.api_key = st.sidebar.text_input("API Key ì…ë ¥", type="password", value=st.session_state.api_key)

# --- Clear ë²„íŠ¼ ---
if st.sidebar.button("ğŸ—‘ï¸ Clear"):
    try:
        client = OpenAI(api_key=st.session_state.api_key)
        if st.session_state.vector_store_id:
            client.beta.vector_stores.delete(st.session_state.vector_store_id)
        st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"âŒ ì‚­ì œ ì‹¤íŒ¨: {e}")
    st.session_state.vector_store_id = None
    st.session_state.assistant_id = None
    st.session_state.chat_history = []

# --- UI êµ¬ì„± ---
st.title("ğŸ“„ ChatPDF")
uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")
question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

# --- GPT ì‘ë‹µ í•¨ìˆ˜ ---
def chat_with_pdf(pdf_file, query):
    client = OpenAI(api_key=st.session_state.api_key)

    # PDF ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(pdf_file.read())
        tmp_path = tmp.name

    # PDF íŒŒì¼ ì—…ë¡œë“œ
    uploaded = client.files.create(file=open(tmp_path, "rb"), purpose="assistants")

    # ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° íŒŒì¼ ì—°ê²°
    vector_store = client.beta.vector_stores.create(name="ChatPDF VectorStore")
    client.beta.vector_stores.file_batches.upload_and_poll(vector_store.id, files=[uploaded.id])
    st.session_state.vector_store_id = vector_store.id

    # Assistant ìƒì„±
    assistant = client.beta.assistants.create(
        name="PDF Assistant",
        instructions="ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.",
        tools=[{"type": "file_search"}],
        model="gpt-4"
    )
    st.session_state.assistant_id = assistant.id

    # Thread ìƒì„± ë° ì§ˆë¬¸ ì¶”ê°€
    thread = client.beta.threads.create()
    client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=query
    )

    # GPT ì‹¤í–‰
    run = client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=assistant.id,
        tool_resources={"file_search": {"vector_store_ids": [vector_store.id]}}
    )

    # ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
    while True:
        run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        if run_status.status == "completed":
            break
        elif run_status.status == "failed":
            return "âŒ ì‹¤í–‰ ì‹¤íŒ¨"
        time.sleep(1)

    # ì‘ë‹µ ì¶”ì¶œ
    messages = client.beta.threads.messages.list(thread_id=thread.id)
    for msg in reversed(messages.data):
        if msg.role == "assistant":
            return msg.content[0].text.value

    return "â“ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."

# --- ì§ˆë¬¸ ì „ì†¡ ---
if st.button("ì „ì†¡") and uploaded_file and question.strip():
    with st.spinner("ğŸ“š GPTê°€ PDFë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        response = chat_with_pdf(uploaded_file, question)
        st.session_state.chat_history.append({"question": question, "answer": response})

# --- ëŒ€í™” ì¶œë ¥ ---
for chat in st.session_state.chat_history:
    st.markdown(f"**ğŸ™‹ ì§ˆë¬¸:** {chat['question']}")
    st.markdown(f"**ğŸ¤– ì‘ë‹µ:** {chat['answer']}")
