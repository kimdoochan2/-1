import streamlit as st
import openai
import tempfile
import time

# âœ… í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ìœ„ì— ìœ„ì¹˜í•´ì•¼ í•¨)
st.set_page_config(page_title="ChatPDF", layout="centered")

# âœ… ë²„ì „ í™•ì¸ (ì„ íƒ)
st.sidebar.write("ğŸ“¦ OpenAI ë²„ì „:", openai.__version__)

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "vector_store_id" not in st.session_state:
    st.session_state.vector_store_id = None
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# âœ… API í‚¤ ì…ë ¥
st.sidebar.header("ğŸ” OpenAI API ì„¤ì •")
st.session_state.api_key = st.sidebar.text_input("API Key ì…ë ¥", type="password", value=st.session_state.api_key)

# âœ… ë²¡í„°ìŠ¤í† ì–´ ì‚­ì œ
if st.sidebar.button("ğŸ—‘ï¸ Clear"):
    try:
        client = openai.OpenAI(api_key=st.session_state.api_key)
        if st.session_state.vector_store_id:
            client.beta.vector_stores.delete(st.session_state.vector_store_id)
        st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"âŒ ì‚­ì œ ì‹¤íŒ¨: {e}")
    st.session_state.vector_store_id = None
    st.session_state.assistant_id = None
    st.session_state.chat_history = []

# âœ… íŒŒì¼ ì—…ë¡œë“œ & ì§ˆë¬¸ ì…ë ¥
st.title("ğŸ“„ ChatPDF")
uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")
question = st.text_input("PDFì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”:")

# âœ… GPT ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜
def chat_with_pdf(pdf_file, query):
    try:
        client = openai.OpenAI(api_key=st.session_state.api_key)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(pdf_file.read())
            tmp_path = tmp.name

        uploaded = client.files.create(file=open(tmp_path, "rb"), purpose="assistants")

        vector_store = client.beta.vector_stores.create(name="ChatPDF VectorStore")
        client.beta.vector_stores.file_batches.upload_and_poll(vector_store.id, files=[uploaded.id])
        st.session_state.vector_store_id = vector_store.id

        assistant = client.beta.assistants.create(
            name="PDF Assistant",
            instructions="ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.",
            tools=[{"type": "file_search"}],
            model="gpt-4"
        )
        st.session_state.assistant_id = assistant.id

        thread = client.beta.threads.create()
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=query
        )

        run = client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=assistant.id,
            tool_resources={"file_search": {"vector_store_ids": [vector_store.id]}}
        )

        while True:
            run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
            if run_status.status == "completed":
                break
            elif run_status.status == "failed":
                return "âŒ GPT ì‹¤í–‰ ì‹¤íŒ¨"
            time.sleep(1)

        messages = client.beta.threads.messages.list(thread_id=thread.id)
        for msg in reversed(messages.data):
            if msg.role == "assistant":
                return msg.content[0].text.value

        return "â“ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}"

# âœ… ì§ˆë¬¸ ì‹¤í–‰
if st.button("ì „ì†¡") and uploaded_file and question.strip():
    with st.spinner("ğŸ“š GPTê°€ PDFë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        response = chat_with_pdf(uploaded_file, question)
        st.session_state.chat_history.append({"question": question, "answer": response})

# âœ… ëŒ€í™” ì¶œë ¥
for chat in st.session_state.chat_history:
    st.markdown(f"**ğŸ™‹ ì§ˆë¬¸:** {chat['question']}")
    st.markdown(f"**ğŸ¤– ì‘ë‹µ:** {chat['answer']}")

